{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMqLCCMvz70RnAkTgdHXptJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lqlBQAWRuAbu"},"outputs":[],"source":["!pip install pypdf2\n","!pip install transformers\n","!pip install torch"]},{"cell_type":"code","source":["from PyPDF2 import PdfReader\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","import re\n","from string import punctuation\n","from transformers import BartForConditionalGeneration, BartTokenizer\n","import torch\n","import unicodedata"],"metadata":{"id":"ep8qEHJzuGko"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n","tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n","reader = PdfReader('W5 ETK Notes.pdf')\n","text = []\n","for page in reader.pages:\n","  text.append(nltk.sent_tokenize(page.extract_text()))"],"metadata":{"id":"4NejSI6bgk5Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["split_text=[]\n","for i in text:\n","  for j in i:\n","    split_text.append(j)"],"metadata":{"id":"qIEBhmezY9qv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cleanup(text):\n","  ltext=text.lower()\n","  ltext = re.sub(f\"[{re.escape(punctuation)}]\", \"\", ltext)\n","  ltext = \" \".join(ltext.split())\n","  remove_chars=['’', ',','‘','•','”','“','—']\n","  for i in remove_chars:\n","    ltext=ltext.replace(i, '')\n","  clean_text = \" \".join(ltext.split())\n","\n","  cl_text=clean_text.split()\n","  la=\"\"\n","  for i in cl_text:\n","    la+=i+\" \"\n","  laa=\"\"\n","  laa+=\"\".join([char for char in la if not unicodedata.category(char) == 'Co'])\n","  return laa\n","chunk_list=[]\n","generated_summaries = []\n","for i in split_text:\n","  cleaned_text=cleanup(i)\n","  chunk_list.append(cleaned_text)"],"metadata":{"id":"29cbvyiskEI2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["length=0\n","nested_list=[]\n","sent_list=[]\n","generated_summaries = []\n","for i in chunk_list:\n","  length+=len(i)\n","  if length<1024:\n","    sent_list.append(i)\n","  else:\n","    nested_list.append(sent_list)\n","    sent_list=[i]\n","    length=0\n","if sent_list:\n","  nested_list.append(sent_list)"],"metadata":{"id":"ADdkqclVeOg8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch_device = 'cuda'\n","generated_summaries = []\n","\n","for i in nested_list:\n","    inputs = tokenizer(' '.join(i), max_length=1000, return_tensors='pt', truncation=True).to(torch_device)\n","    inputs = {key: val.to(torch_device) for key, val in inputs.items()}\n","    summary_ids = model.to(torch_device).generate(inputs['input_ids'])\n","\n","    summary = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n","    generated_summaries.append(summary)\n"],"metadata":{"id":"nI8xVy5uTuI5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generated_summaries"],"metadata":{"id":"ol2JEFMY86hp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["summarizedText=\"\"\n","for i in generated_summaries:\n","  for j in i:\n","    summarizedText+=j+\" \""],"metadata":{"id":"VNkJI4Y1h7vJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["summarizedText"],"metadata":{"id":"S_157u-8j_ca"},"execution_count":null,"outputs":[]}]}